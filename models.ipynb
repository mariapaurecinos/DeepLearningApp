{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e74c5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and Keras for deep learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# For handling the dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#Classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "import re, string, tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1541f8",
   "metadata": {},
   "source": [
    "# Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e594edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ef14ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "(train_images, train_labels),(test_images, test_labels) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2f2ff004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#explore data\n",
    "# Visualize one image\n",
    "plt.imshow(train_images[0], cmap=\"gray\")\n",
    "plt.title(f\"Label: {train_labels[0]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a3c0b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def preprocess_images(\n",
    "        images: np.ndarray,\n",
    "        labels: np.ndarray | None = None,\n",
    "        flatten: bool = True,\n",
    "        one_hot: bool = False,\n",
    "        num_classes: int | None = None\n",
    ") -> Tuple[np.ndarray, np.ndarray | None]:\n",
    "\n",
    "    # 1. Normalización\n",
    "    images = images / 255.0\n",
    "\n",
    "    # 2. Opcionalmente aplanar\n",
    "    ''' images.shape[0] → número de muestras N'''\n",
    "    '''-1 indica a NumPy que “calcule automáticamente” el tamaño de \n",
    "    la dimensión que falta usando el producto de las dimensiones restantes.'''\n",
    "    if flatten:\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "        \n",
    "\n",
    "    # 3. Procesar labels si vienen\n",
    "    if labels is not None:\n",
    "        if one_hot:\n",
    "            if num_classes is None:\n",
    "                num_classes = int(np.max(labels)) + 1\n",
    "            labels = np.eye(num_classes, dtype='float32')[labels]\n",
    "        return images, labels\n",
    "    else:\n",
    "        return images, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "315e7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para una red densa (aplanamos):\n",
    "#“Aplanar” (o flatten) una imagen significa convertir su arreglo multidimensional — \n",
    "# que conserva la estructura espacial de alto × ancho × canales — en un vector de una sola dimensión.\n",
    "train_images_pr, train_labels_pr = preprocess_images(train_images, train_labels, flatten=True, one_hot=False, num_classes=10)\n",
    "test_images_pr,  test_labels_pr  = preprocess_images(test_images,  test_labels,  flatten=True, one_hot=False, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c1bd1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# BUILD THE MODEL\n",
    "'''la última layer debe ser de 10 porque son 10 clases de respuesta\n",
    "el activation que se debe usar para reconocer imágenes es softmax'''\n",
    "model_image = Sequential([\n",
    "    layers.Dense(128, activation='softmax', input_shape=(3072,)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "85cd1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILE THE MODEL\n",
    "model_image.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dd1aac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1635 - loss: 2.2051 - val_accuracy: 0.1814 - val_loss: 2.1081\n",
      "Epoch 2/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1771 - loss: 2.1046 - val_accuracy: 0.1828 - val_loss: 2.1159\n",
      "Epoch 3/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1792 - loss: 2.0877 - val_accuracy: 0.1932 - val_loss: 2.0773\n",
      "Epoch 4/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1861 - loss: 2.0790 - val_accuracy: 0.2066 - val_loss: 2.0816\n",
      "Epoch 5/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2031 - loss: 2.0568 - val_accuracy: 0.2136 - val_loss: 2.0426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18fa9232860>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAIN THE MODEL\n",
    "model_image.fit(train_images_pr, train_labels_pr,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "701f0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2227 - loss: 2.0334\n",
      "Accuracy Image Recognition: 0.21279999613761902\n"
     ]
    }
   ],
   "source": [
    "#EVALUATE\n",
    "loss, acc = model_image.evaluate(test_images_pr, test_labels_pr)\n",
    "print(\"Accuracy Image Recognition:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b69fa85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTION\n",
    "def image_prediction(image):\n",
    "    # --- predice ---\n",
    "    probs = model_image.predict(image)\n",
    "    pred_class = np.argmax(probs, axis=1)[0] \n",
    "\n",
    "    return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7e5ef212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Predicción de la imagen: 6\n"
     ]
    }
   ],
   "source": [
    "#ejemplo de prediccion\n",
    "sample = np.expand_dims(test_images_pr[5], axis=0) #se debe usar una imagen con el mismo preprocesamiento\n",
    "sample_image_pred =  image_prediction(sample)\n",
    "print(\"Predicción de la imagen:\", sample_image_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aa835b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicciones con test\n",
    "image_predictions_test = model_image.predict(test_images_pr)\n",
    "image_predicted_labels = np.argmax(image_predictions_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d7104e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_114 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m393,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_115 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,904</span> (4.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,183,904\u001b[0m (4.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,634</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,634\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">789,270</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m789,270\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_image.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "39573ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image.save('model_image.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "60b57643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.04      0.07      1000\n",
      "           1       0.34      0.39      0.36      1000\n",
      "           2       0.11      0.02      0.04      1000\n",
      "           3       0.16      0.04      0.06      1000\n",
      "           4       0.11      0.02      0.03      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.17      0.84      0.29      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.24      0.77      0.37      1000\n",
      "           9       0.17      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.21     10000\n",
      "   macro avg       0.15      0.21      0.12     10000\n",
      "weighted avg       0.15      0.21      0.12     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(test_labels, image_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705048ca",
   "metadata": {},
   "source": [
    "# TEXT CLASSIFICATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "aa9cd4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 80.2M    0 32768    0     0  61149      0  0:22:55 --:--:--  0:22:55 61248\n",
      "  0 80.2M    0  512k    0     0   332k      0  0:04:07  0:00:01  0:04:06  332k\n",
      "  1 80.2M    1 1360k    0     0   532k      0  0:02:34  0:00:02  0:02:32  532k\n",
      "  3 80.2M    3 3008k    0     0   850k      0  0:01:36  0:00:03  0:01:33  850k\n",
      "  6 80.2M    6 5104k    0     0  1119k      0  0:01:13  0:00:04  0:01:09 1119k\n",
      "  8 80.2M    8 7264k    0     0  1307k      0  0:01:02  0:00:05  0:00:57 1440k\n",
      " 11 80.2M   11 9056k    0     0  1383k      0  0:00:59  0:00:06  0:00:53 1707k\n",
      " 12 80.2M   12 10.2M    0     0  1391k      0  0:00:59  0:00:07  0:00:52 1830k\n",
      " 14 80.2M   14 11.5M    0     0  1381k      0  0:00:59  0:00:08  0:00:51 1755k\n",
      " 16 80.2M   16 13.0M    0     0  1398k      0  0:00:58  0:00:09  0:00:49 1652k\n",
      " 18 80.2M   18 14.4M    0     0  1404k      0  0:00:58  0:00:10  0:00:48 1513k\n",
      " 19 80.2M   19 15.7M    0     0  1395k      0  0:00:58  0:00:11  0:00:47 1411k\n",
      " 20 80.2M   20 16.7M    0     0  1371k      0  0:00:59  0:00:12  0:00:47 1341k\n",
      " 22 80.2M   22 17.8M    0     0  1348k      0  0:01:00  0:00:13  0:00:47 1290k\n",
      " 23 80.2M   23 18.8M    0     0  1330k      0  0:01:01  0:00:14  0:00:47 1200k\n",
      " 24 80.2M   24 20.0M    0     0  1316k      0  0:01:02  0:00:15  0:00:47 1132k\n",
      " 26 80.2M   26 21.1M    0     0  1305k      0  0:01:02  0:00:16  0:00:46 1098k\n",
      " 27 80.2M   27 22.0M    0     0  1286k      0  0:01:03  0:00:17  0:00:46 1074k\n",
      " 28 80.2M   28 22.6M    0     0  1250k      0  0:01:05  0:00:18  0:00:47  985k\n",
      " 28 80.2M   28 23.2M    0     0  1217k      0  0:01:07  0:00:19  0:00:48  890k\n",
      " 29 80.2M   29 23.8M    0     0  1191k      0  0:01:08  0:00:20  0:00:48  799k\n",
      " 30 80.2M   30 24.5M    0     0  1168k      0  0:01:10  0:00:21  0:00:49  712k\n",
      " 31 80.2M   31 25.2M    0     0  1148k      0  0:01:11  0:00:22  0:00:49  658k\n",
      " 32 80.2M   32 25.9M    0     0  1127k      0  0:01:12  0:00:23  0:00:49  671k\n",
      " 33 80.2M   33 26.5M    0     0  1109k      0  0:01:14  0:00:24  0:00:50  685k\n",
      " 34 80.2M   34 27.2M    0     0  1093k      0  0:01:15  0:00:25  0:00:50  691k\n",
      " 34 80.2M   34 27.9M    0     0  1078k      0  0:01:16  0:00:26  0:00:50  688k\n",
      " 35 80.2M   35 28.5M    0     0  1063k      0  0:01:17  0:00:27  0:00:50  682k\n",
      " 36 80.2M   36 29.3M    0     0  1051k      0  0:01:18  0:00:28  0:00:50  694k\n",
      " 37 80.2M   37 30.0M    0     0  1041k      0  0:01:18  0:00:29  0:00:49  707k\n",
      " 38 80.2M   38 30.7M    0     0  1030k      0  0:01:19  0:00:30  0:00:49  710k\n",
      " 39 80.2M   39 31.4M    0     0  1021k      0  0:01:20  0:00:31  0:00:49  719k\n",
      " 40 80.2M   40 32.1M    0     0  1011k      0  0:01:21  0:00:32  0:00:49  730k\n",
      " 41 80.2M   41 32.9M    0     0  1004k      0  0:01:21  0:00:33  0:00:48  734k\n",
      " 41 80.2M   41 33.6M    0     0   997k      0  0:01:22  0:00:34  0:00:48  740k\n",
      " 43 80.2M   43 34.5M    0     0   996k      0  0:01:22  0:00:35  0:00:47  785k\n",
      " 44 80.2M   44 35.5M    0     0   996k      0  0:01:22  0:00:36  0:00:46  842k\n",
      " 45 80.2M   45 36.5M    0     0   997k      0  0:01:22  0:00:37  0:00:45  899k\n",
      " 46 80.2M   46 37.5M    0     0   997k      0  0:01:22  0:00:38  0:00:44  954k\n",
      " 48 80.2M   48 38.5M    0     0   999k      0  0:01:22  0:00:39  0:00:43 1007k\n",
      " 49 80.2M   49 39.6M    0     0   999k      0  0:01:22  0:00:40  0:00:42 1026k\n",
      " 50 80.2M   50 40.5M    0     0  1000k      0  0:01:22  0:00:41  0:00:41 1029k\n",
      " 51 80.2M   51 41.6M    0     0  1002k      0  0:01:21  0:00:42  0:00:39 1042k\n",
      " 53 80.2M   53 42.7M    0     0  1003k      0  0:01:21  0:00:43  0:00:38 1047k\n",
      " 54 80.2M   54 43.4M    0     0  1000k      0  0:01:22  0:00:44  0:00:38 1007k\n",
      " 55 80.2M   55 44.3M    0     0   997k      0  0:01:22  0:00:45  0:00:37  978k\n",
      " 56 80.2M   56 45.1M    0     0   992k      0  0:01:22  0:00:46  0:00:36  923k\n",
      " 56 80.2M   56 45.5M    0     0   980k      0  0:01:23  0:00:47  0:00:36  796k\n",
      " 57 80.2M   57 45.8M    0     0   967k      0  0:01:24  0:00:48  0:00:36  655k\n",
      " 57 80.2M   57 46.2M    0     0   955k      0  0:01:25  0:00:49  0:00:36  557k\n",
      " 58 80.2M   58 46.5M    0     0   943k      0  0:01:27  0:00:50  0:00:37  455k\n",
      " 58 80.2M   58 46.9M    0     0   932k      0  0:01:28  0:00:51  0:00:37  367k\n",
      " 58 80.2M   58 47.2M    0     0   920k      0  0:01:29  0:00:52  0:00:37  349k\n",
      " 59 80.2M   59 47.5M    0     0   909k      0  0:01:30  0:00:53  0:00:37  343k\n",
      " 59 80.2M   59 47.9M    0     0   899k      0  0:01:31  0:00:54  0:00:37  349k\n",
      " 60 80.2M   60 48.3M    0     0   891k      0  0:01:32  0:00:55  0:00:37  360k\n",
      " 60 80.2M   60 48.7M    0     0   883k      0  0:01:33  0:00:56  0:00:37  374k\n",
      " 61 80.2M   61 49.2M    0     0   876k      0  0:01:33  0:00:57  0:00:36  409k\n",
      " 61 80.2M   61 49.7M    0     0   869k      0  0:01:34  0:00:58  0:00:36  445k\n",
      " 62 80.2M   62 50.2M    0     0   864k      0  0:01:35  0:00:59  0:00:36  481k\n",
      " 63 80.2M   63 50.9M    0     0   861k      0  0:01:35  0:01:00  0:00:35  529k\n",
      " 64 80.2M   64 51.9M    0     0   864k      0  0:01:35  0:01:01  0:00:34  656k\n",
      " 66 80.2M   66 53.1M    0     0   871k      0  0:01:34  0:01:02  0:00:32  810k\n",
      " 68 80.2M   68 54.7M    0     0   881k      0  0:01:33  0:01:03  0:00:30 1018k\n",
      " 70 80.2M   70 56.2M    0     0   892k      0  0:01:32  0:01:04  0:00:28 1219k\n",
      " 71 80.2M   71 57.7M    0     0   901k      0  0:01:31  0:01:05  0:00:26 1389k\n",
      " 73 80.2M   73 59.2M    0     0   911k      0  0:01:30  0:01:06  0:00:24 1498k\n",
      " 76 80.2M   76 61.1M    0     0   926k      0  0:01:28  0:01:07  0:00:21 1613k\n",
      " 78 80.2M   78 63.1M    0     0   943k      0  0:01:27  0:01:08  0:00:19 1721k\n",
      " 81 80.2M   81 65.0M    0     0   957k      0  0:01:25  0:01:09  0:00:16 1800k\n",
      " 81 80.2M   81 65.3M    0     0   949k      0  0:01:26  0:01:10  0:00:16 1575k\n",
      " 81 80.2M   81 65.5M    0     0   938k      0  0:01:27  0:01:11  0:00:16 1290k\n",
      " 82 80.2M   82 65.7M    0     0   928k      0  0:01:28  0:01:12  0:00:16  961k\n",
      " 82 80.2M   82 66.2M    0     0   921k      0  0:01:29  0:01:13  0:00:16  630k\n",
      " 83 80.2M   83 66.8M    0     0   918k      0  0:01:29  0:01:14  0:00:15  372k\n",
      " 84 80.2M   84 67.6M    0     0   917k      0  0:01:29  0:01:15  0:00:14  466k\n",
      " 85 80.2M   85 68.6M    0     0   918k      0  0:01:29  0:01:16  0:00:13  636k\n",
      " 87 80.2M   87 69.9M    0     0   923k      0  0:01:28  0:01:17  0:00:11  843k\n",
      " 88 80.2M   88 71.3M    0     0   929k      0  0:01:28  0:01:18  0:00:10 1045k\n",
      " 90 80.2M   90 72.9M    0     0   938k      0  0:01:27  0:01:19  0:00:08 1247k\n",
      " 93 80.2M   93 74.7M    0     0   950k      0  0:01:26  0:01:20  0:00:06 1451k\n",
      " 95 80.2M   95 76.7M    0     0   963k      0  0:01:25  0:01:21  0:00:04 1646k\n",
      " 98 80.2M   98 78.9M    0     0   979k      0  0:01:23  0:01:22  0:00:01 1844k\n",
      "100 80.2M  100 80.2M    0     0   988k      0  0:01:23  0:01:23 --:--:-- 1978k\n"
     ]
    }
   ],
   "source": [
    "#IMPORT THE DATA\n",
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "afbb6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrames\n",
    "dataset_dir = \"aclImdb\"            \n",
    "train_dir_text   = os.path.join(dataset_dir, \"train\")\n",
    "test_dir_text    = os.path.join(dataset_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "67c2bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 60000 files for training.\n",
      "Found 75000 files belonging to 3 classes.\n",
      "Using 15000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 2) Create the raw tf.data.Datasets\n",
    "batch_size = 32\n",
    "raw_train_ds = keras.utils.text_dataset_from_directory(\n",
    "    train_dir_text,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_val_ds = keras.utils.text_dataset_from_directory(\n",
    "    train_dir_text,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_test_ds = keras.utils.text_dataset_from_directory(\n",
    "    test_dir_text,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "14817a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer guardado ✔️\n"
     ]
    }
   ],
   "source": [
    "train_sentences = []\n",
    "for batch_x, _ in raw_train_ds:           # batch_x es un tensor (B,)\n",
    "    for t in batch_x.numpy():             # pasa a bytes\n",
    "        train_sentences.append(t.decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "### Script completo (opción 1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# 1️⃣  Sacar frases individuales\n",
    "train_sentences_ds = raw_train_ds.unbatch().map(lambda x, y: x)\n",
    "train_sentences = [t.decode(\"utf-8\")                 # <-- a string\n",
    "                   for t in train_sentences_ds.as_numpy_iterator()]\n",
    "\n",
    "# 2️⃣  Ajustar tokenizer\n",
    "tokenizer = Tokenizer(num_words=15_000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "# 3️⃣  Guardar\n",
    "joblib.dump(tokenizer, \"text_tokenizer.pkl\")\n",
    "print(\"Tokenizer guardado ✔️\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f4a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 15_000\n",
    "SEQ_LEN    = 400\n",
    "\n",
    "# --- a) capa de estandarización -------------------------------\n",
    "def custom_standardize(x):\n",
    "    x = tf.strings.lower(x)\n",
    "    x = tf.strings.regex_replace(x, \"<br />\", \" \")\n",
    "    x = tf.strings.regex_replace(x, r\"[^\\w\\s]\", \"\")   # quita puntuación\n",
    "    return x\n",
    "\n",
    "# --- b) capa de vectorización ---------------------------------\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardize,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQ_LEN\n",
    ")\n",
    "\n",
    "# --- c) adaptar solo con texto de entrenamiento ----------------\n",
    "vectorize_layer.adapt(\n",
    "    raw_train_ds.map(lambda txt, lbl: txt)            # <-- SOLO strings\n",
    ")\n",
    "\n",
    "# --- d) función para aplicar la capa ---------------------------\n",
    "def vectorize_batch(text, label):\n",
    "    text = tf.expand_dims(text, -1)                   # añade eje \"canal\"\n",
    "    return vectorize_layer(text), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474205e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- e) datasets finales --------------------------------------\n",
    "train_ds = (raw_train_ds\n",
    "            .map(vectorize_batch)\n",
    "            .cache()\n",
    "            .prefetch(10))\n",
    "\n",
    "val_ds   = (raw_val_ds\n",
    "            .map(vectorize_batch)\n",
    "            .cache()\n",
    "            .prefetch(10))\n",
    "\n",
    "test_ds  = (raw_test_ds\n",
    "            .map(vectorize_batch)\n",
    "            .cache()\n",
    "            .prefetch(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extraer sólo las etiquetas, lote a lote\n",
    "test_labes_text = test_ds.map(lambda txt, lbl: lbl).as_numpy_iterator()\n",
    "\n",
    "# 2. Concatenar todos los lotes en un vector 1-D\n",
    "text_labels_true = np.concatenate([batch for batch in test_labes_text], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd414a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from typing import Tuple\n",
    "\n",
    "def preprocess_text(\n",
    "        train_raw: tf.data.Dataset | None = None,    # puede venir None al re-usar\n",
    "        val_raw:   tf.data.Dataset | None = None,\n",
    "        test_raw:  tf.data.Dataset | None = None,\n",
    "        *,\n",
    "        vectorizer: layers.TextVectorization | None = None,  # <-- NUEVO\n",
    "        max_tokens: int = 15_000,\n",
    "        seq_len:    int = 400,\n",
    "        cache:      bool = True,\n",
    "        prefetch:   int  = 10\n",
    ") -> Tuple[tf.data.Dataset | None,\n",
    "           tf.data.Dataset | None,\n",
    "           tf.data.Dataset | None,\n",
    "           layers.TextVectorization]:\n",
    "    \"\"\"\n",
    "    Devuelve datasets vectorizados y UNA sola capa TextVectorization.\n",
    "\n",
    "    Si 'vectorizer' es None se crea y se adapta con 'train_raw'.\n",
    "    Si se pasa una capa ya adaptada, se reutiliza sin repetir el .adapt().\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Función de estandarización -----------------------------\n",
    "    def _standardize(x: tf.Tensor) -> tf.Tensor:\n",
    "        x = tf.strings.lower(x)\n",
    "        x = tf.strings.regex_replace(x, \"<br />\", \" \")\n",
    "        x = tf.strings.regex_replace(x,\n",
    "                                     f\"[{re.escape(string.punctuation)}]\", \"\")\n",
    "        return x\n",
    "\n",
    "    # --- 2. Crear / reutilizar la capa -----------------------------\n",
    "    if vectorizer is None:\n",
    "        vectorizer = layers.TextVectorization(\n",
    "            standardize=_standardize,\n",
    "            max_tokens=max_tokens,\n",
    "            output_mode=\"int\",\n",
    "            output_sequence_length=seq_len,\n",
    "        )\n",
    "        if train_raw is None:\n",
    "            raise ValueError(\"Necesito 'train_raw' para adaptar el vocabulario\")\n",
    "        # A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6af7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_text, val_ds_text, test_ds_text, vect = preprocess_text(\n",
    "    raw_train_ds, raw_val_ds, raw_test_ds,\n",
    "    max_tokens=15_000,\n",
    "    seq_len=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import re, string, tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from typing import Tuple\n",
    "\n",
    "def preprocess_text(\n",
    "        train_raw: tf.data.Dataset | None = None,    # puede venir None al re-usar\n",
    "        val_raw:   tf.data.Dataset | None = None,\n",
    "        test_raw:  tf.data.Dataset | None = None,\n",
    "        *,\n",
    "        vectorizer: layers.TextVectorization | None = None,  # <-- NUEVO\n",
    "        max_tokens: int = 15_000,\n",
    "        seq_len:    int = 400,\n",
    "        cache:      bool = True,\n",
    "        prefetch:   int  = 10\n",
    ") -> Tuple[tf.data.Dataset | None,\n",
    "           tf.data.Dataset | None,\n",
    "           tf.data.Dataset | None,\n",
    "           layers.TextVectorization]:\n",
    "    \"\"\"\n",
    "    Devuelve datasets vectorizados y UNA sola capa TextVectorization.\n",
    "\n",
    "    Si 'vectorizer' es None se crea y se adapta con 'train_raw'.\n",
    "    Si se pasa una capa ya adaptada, se reutiliza sin repetir el .adapt().\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Función de estandarización -----------------------------\n",
    "    def _standardize(x: tf.Tensor) -> tf.Tensor:\n",
    "        x = tf.strings.lower(x)\n",
    "        x = tf.strings.regex_replace(x, \"<br />\", \" \")\n",
    "        x = tf.strings.regex_replace(x,\n",
    "                                     f\"[{re.escape(string.punctuation)}]\", \"\")\n",
    "        return x\n",
    "\n",
    "    # --- 2. Crear / reutilizar la capa -----------------------------\n",
    "    if vectorizer is None:\n",
    "        vectorizer = layers.TextVectorization(\n",
    "            standardize=_standardize,\n",
    "            max_tokens=max_tokens,\n",
    "            output_mode=\"int\",\n",
    "            output_sequence_length=seq_len,\n",
    "        )\n",
    "        if train_raw is None:\n",
    "            raise ValueError(\"Necesito 'train_raw' para adaptar el vocabulario\")\n",
    "        # Adaptar SOLO una vez\n",
    "        vectorizer.adapt(train_raw.map(lambda txt, lbl: txt))\n",
    "\n",
    "    # --- 3. Función para aplicar la capa ---------------------------\n",
    "    def _vectorize(text: tf.Tensor, label: tf.Tensor):\n",
    "        text = tf.expand_dims(text, -1)\n",
    "        return vectorizer(text), label\n",
    "\n",
    "    def _prep(ds: tf.data.Dataset | None):\n",
    "        if ds is None:\n",
    "            return None\n",
    "        ds = ds.map(_vectorize)\n",
    "        if cache:\n",
    "            ds = ds.cache()\n",
    "        return ds.prefetch(prefetch)\n",
    "\n",
    "    # --- 4. Procesar splits ---------------------------------------\n",
    "    train_ds = _prep(train_raw)\n",
    "    val_ds   = _prep(val_raw)\n",
    "    test_ds  = _prep(test_raw)\n",
    "\n",
    "    return train_ds, val_ds, test_ds, vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds, vec_layer = preprocess_text(\n",
    "    train_raw=raw_train_ds,\n",
    "    val_raw  =raw_val_ds,\n",
    "    test_raw =raw_test_ds,\n",
    "    max_tokens=15_000,\n",
    "    seq_len=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7776de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.6070 - loss: 0.6097 - val_accuracy: 0.8574 - val_loss: 0.3317\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.8877 - loss: 0.2771 - val_accuracy: 0.8820 - val_loss: 0.3030\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.9412 - loss: 0.1584 - val_accuracy: 0.8690 - val_loss: 0.4160\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - accuracy: 0.9674 - loss: 0.0905 - val_accuracy: 0.8562 - val_loss: 0.5288\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.9800 - loss: 0.0556 - val_accuracy: 0.8128 - val_loss: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18f1519d3c0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Construir el modelo con los valores por defecto\n",
    "text_model = model_text()\n",
    "\n",
    "# 2) Entrenar\n",
    "text_model.fit(train_ds_text,\n",
    "          validation_data=val_ds_text,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.8071 - loss: 0.9787\n",
      "Accuracy en test: 80.68%\n"
     ]
    }
   ],
   "source": [
    "# 3) Evaluar\n",
    "loss, acc = text_model.evaluate(test_ds_text)\n",
    "print(f\"Accuracy en test: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3020e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'si  >0.5 es clase positiva\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probar la prediccion con test \n",
    "text_predictions = text_model.predict(test_ds_text)\n",
    "text_pred_labels = (text_predictions > 0.5).astype(\"int32\").ravel() #model.predict(test_ds) devuelve probabilidades \n",
    "''''si  >0.5 es clase positiva'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict 1 texto\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def predict_single_sentence(sentence: str,\n",
    "                            model      = text_model,\n",
    "                            vectorizer = vectorize_layer,\n",
    "                            threshold  = 0.5) -> tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Devuelve (etiqueta, probabilidad) para una frase.\n",
    "\n",
    "    - sentence   : texto crudo.\n",
    "    - model      : modelo entrenado (salida sigmoide).\n",
    "    - vectorizer : capa TextVectorization ya adaptada.\n",
    "    - threshold  : corte para 0/1 (default 0.5).\n",
    "    \"\"\"\n",
    "    # 1) Tensor lote-1 con el texto\n",
    "    txt_tensor = tf.constant([sentence])\n",
    "\n",
    "    # 2) Vectorizar → secuencia shape (1, seq_len)\n",
    "    seq = vectorizer(txt_tensor)\n",
    "\n",
    "    # 3) Predicción de probabilidad positiva\n",
    "    prob = float(model.predict(seq, verbose=0)[0][0])\n",
    "\n",
    "    # 4) Convertir a clase 0/1\n",
    "    label = int(prob > threshold)\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b14afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I loved the movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "label_prueba = predict_single_sentence(text)\n",
    "print(label_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9d8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.34      0.41     12500\n",
      "           1       0.50      0.65      0.57     12500\n",
      "\n",
      "    accuracy                           0.50     25000\n",
      "   macro avg       0.50      0.50      0.49     25000\n",
      "weighted avg       0.50      0.50      0.49     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(text_labels_true, text_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8272977",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.save('model_text.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00433e",
   "metadata": {},
   "source": [
    "# REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import joblib   # para el scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22757611",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42          # Para reproducibilidad\n",
    "EPOCHS        = 50\n",
    "BATCH_SIZE    = 16\n",
    "MODEL_PATH    = \"diabetes_regressor.keras\"\n",
    "SCALER_PATH   = \"scaler.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparación de datos\n",
    "# ---------------------------------------------------------------------------\n",
    "def load_data(test_size: float = 0.2, random_state: int = RANDOM_STATE):\n",
    "    \"\"\"Carga Diabetes e infla train/test.\"\"\"\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    return train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        shuffle=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee93158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2. Arquitectura del modelo\n",
    "# ---------------------------------------------------------------------------\n",
    "def build_keras_model(n_features: int) -> keras.Sequential:\n",
    "    \"\"\"Crea un MLP sencillo para regresión.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(n_features,)),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1)                      # activación linear por defecto\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pipeline (Scaler + Keras)\n",
    "# ---------------------------------------------------------------------------\n",
    "def build_pipeline(n_features: int) -> Pipeline:\n",
    "    \"\"\"Devuelve un pipeline que normaliza y entrena Keras.\"\"\"\n",
    "    keras_reg = KerasRegressor(\n",
    "        model=lambda: build_keras_model(n_features),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=0,\n",
    "        random_state=RANDOM_STATE,  # asegura que KFold interno sea reproducible\n",
    "    )\n",
    "    return Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"regressor\", keras_reg)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 4. Entrenamiento, evaluación y guardado\n",
    "# ---------------------------------------------------------------------------\n",
    "def train_and_evaluate():\n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    pipe = build_pipeline(n_features)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # -- Evaluación con CV sobre TODO el set (scikit cuida el scaling dentro) --\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    neg_mse = cross_val_score(\n",
    "        pipe,       # el pipeline (no solo el estimador)\n",
    "        X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "    mse_scores = -neg_mse\n",
    "    print(\"MSE por fold :\", mse_scores)\n",
    "    print(\"MSE promedio  :\", mse_scores.mean())\n",
    "\n",
    "    # -- Guardar artefactos --\n",
    "    # 1) Modelo Keras (extraído desde el wrapper ya entrenado)\n",
    "    keras_model = pipe.named_steps[\"regressor\"].model_\n",
    "    keras_model.save(MODEL_PATH)        # ➜ diabetes_regressor.keras\n",
    "\n",
    "    # 2) Scaler ya ajustado\n",
    "    scaler = pipe.named_steps[\"scaler\"]\n",
    "    joblib.dump(scaler, SCALER_PATH)    # ➜ scaler.pkl\n",
    "\n",
    "    print(f\"✓ Modelo guardado en {MODEL_PATH}\")\n",
    "    print(f\"✓ Scaler guardado en {SCALER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 782, in predict\n",
      "    with _raise_or_warn_if_not_fitted(self):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 60, in _raise_or_warn_if_not_fitted\n",
      "    check_is_fitted(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1756, in check_is_fitted\n",
      "    if not _is_fitted(estimator, attributes, all_or_any):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1665, in _is_fitted\n",
      "    return estimator.__sklearn_is_fitted__()\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1321, in __sklearn_is_fitted__\n",
      "    check_is_fitted(last_step)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1751, in check_is_fitted\n",
      "    tags = get_tags(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 613, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 782, in predict\n",
      "    with _raise_or_warn_if_not_fitted(self):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 60, in _raise_or_warn_if_not_fitted\n",
      "    check_is_fitted(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1756, in check_is_fitted\n",
      "    if not _is_fitted(estimator, attributes, all_or_any):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1665, in _is_fitted\n",
      "    return estimator.__sklearn_is_fitted__()\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1321, in __sklearn_is_fitted__\n",
      "    check_is_fitted(last_step)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1751, in check_is_fitted\n",
      "    tags = get_tags(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 613, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 782, in predict\n",
      "    with _raise_or_warn_if_not_fitted(self):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 60, in _raise_or_warn_if_not_fitted\n",
      "    check_is_fitted(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1756, in check_is_fitted\n",
      "    if not _is_fitted(estimator, attributes, all_or_any):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1665, in _is_fitted\n",
      "    return estimator.__sklearn_is_fitted__()\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1321, in __sklearn_is_fitted__\n",
      "    check_is_fitted(last_step)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1751, in check_is_fitted\n",
      "    tags = get_tags(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 613, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 782, in predict\n",
      "    with _raise_or_warn_if_not_fitted(self):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 60, in _raise_or_warn_if_not_fitted\n",
      "    check_is_fitted(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1756, in check_is_fitted\n",
      "    if not _is_fitted(estimator, attributes, all_or_any):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1665, in _is_fitted\n",
      "    return estimator.__sklearn_is_fitted__()\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1321, in __sklearn_is_fitted__\n",
      "    check_is_fitted(last_step)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1751, in check_is_fitted\n",
      "    tags = get_tags(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 613, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE por fold : [nan nan nan nan nan]\n",
      "MSE promedio  : nan\n",
      "✓ Modelo guardado en diabetes_regressor.keras\n",
      "✓ Scaler guardado en scaler.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 782, in predict\n",
      "    with _raise_or_warn_if_not_fitted(self):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 60, in _raise_or_warn_if_not_fitted\n",
      "    check_is_fitted(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1756, in check_is_fitted\n",
      "    if not _is_fitted(estimator, attributes, all_or_any):\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1665, in _is_fitted\n",
      "    return estimator.__sklearn_is_fitted__()\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 1321, in __sklearn_is_fitted__\n",
      "    check_is_fitted(last_step)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1751, in check_is_fitted\n",
      "    tags = get_tags(estimator)\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "  File \"c:\\Users\\Maria Paula\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 613, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
