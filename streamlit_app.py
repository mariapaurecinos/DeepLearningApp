"""
Streamlit multi-model deployment demo (flat layout)
==================================================

Esta versi√≥n usa los nombres **exactos** que aparecen en tu carpeta:

```
‚îú‚îÄ‚îÄ model_image.keras          # CNN de im√°genes (CIFAR-10, etc.)
‚îú‚îÄ‚îÄ model_text.keras           # Clasificador de texto (sentiment)
‚îú‚îÄ‚îÄ diabetes_regressor.keras   # Modelo de regresi√≥n (ej. Diabetes)
‚îú‚îÄ‚îÄ scaler.pkl                 # (opcional) StandardScaler u otro pre-procesador
‚îú‚îÄ‚îÄ text_tokenizer.pkl         # Tokenizer de Keras --> lo crear√°s t√∫
‚îú‚îÄ‚îÄ streamlit_app.py           # <‚Äî este archivo
‚îî‚îÄ‚îÄ requirements.txt
```

> Si entrenaste tu modelo de regresi√≥n con un `StandardScaler`, d√©jalo guardado en
> `scaler.pkl`.  Si no, simplemente elimina el fichero y el c√≥digo lo ignorar√°.

Lanza con:

```bash
pip install -r requirements.txt
streamlit run streamlit_app.py
```
"""

from __future__ import annotations

import numpy as np
import streamlit as st
from pathlib import Path
from PIL import Image
import joblib

# --------------------------------------------------------------
#  Carga perezosa de TensorFlow para acelerar las p√°ginas que
#  no lo necesitan (hasta que el usuario lo requiera).
# --------------------------------------------------------------

def _lazy_tf():
    import tensorflow as tf  # pylint: disable=import-error
    return tf

# ------------------ LOADERS CON CACH√â ------------------------

@st.cache_resource(show_spinner=False)
def load_image_model():
    tf = _lazy_tf()
    return tf.keras.models.load_model("model_image.keras")

@st.cache_resource(show_spinner=False)
def load_text_model():
    tf = _lazy_tf()
    return tf.keras.models.load_model("model_text.keras")

@st.cache_resource(show_spinner=False)
def load_regression_model():
    tf = _lazy_tf()
    return tf.keras.models.load_model("diabetes_regressor.keras")

@st.cache_resource(show_spinner=False)
def load_tokenizer():
    return joblib.load("text_tokenizer.pkl")

@st.cache_resource(show_spinner=False)
def load_scaler():
    path = Path("scaler.pkl")
    return joblib.load(path) if path.exists() else None

# ------------------ CONSTANTES A EDITAR ----------------------

IMAGE_SIZE: tuple[int, int] = (32, 32)  # tama√±o de entrada del CNN
IMAGE_CLASS_NAMES: list[str] = [
    "Airplane", "Automobile", "Bird", "Cat", "Deer",
    "Dog", "Frog", "Horse", "Ship", "Truck",
]  # ajusta al orden de tu modelo

TEXT_MAXLEN: int = 400  # longitud de secuencia usada en entrenamiento

FEATURE_NAMES: list[str] = [
    # pon aqu√≠ las columnas (en orden) del set de entrenamiento del modelo de regresi√≥n
    "age", "sex", "bmi", "average blood pressure", "total serum cholesterol", " low-density lipoproteins", "high-density lipoprotein", " total cholesterol / HDL", "serum triglycerides level", " blood sugar level",
]

# ------------------ CONFIGURACI√ìN UI -------------------------

st.set_page_config(
    page_title="üß† Multi-Model Demo",
    layout="centered",
    initial_sidebar_state="expanded",
)

st.title("üß† Multi-Model Prediction Demo")

pagina = st.sidebar.selectbox(
    "Elige el modelo a probar:",
    ("Clasificaci√≥n de Imagen", "Clasificaci√≥n de Texto", "Regresi√≥n"),
)

# ------------------ P√ÅGINA: IMAGEN ---------------------------
import numpy as np
from typing import Tuple

def preprocess_images(
        images: np.ndarray,
        labels: np.ndarray | None = None,
        flatten: bool = True,
        one_hot: bool = False,
        num_classes: int | None = None
) -> Tuple[np.ndarray, np.ndarray | None]:

    images = images / 255.0

    if flatten:
        images = images.reshape(images.shape[0], -1)

    if labels is not None:
        if one_hot:
            if num_classes is None:
                num_classes = int(np.max(labels)) + 1
            labels = np.eye(num_classes, dtype='float32')[labels]
        return images, labels
    else:
        return images, None

if pagina == "Clasificaci√≥n de Imagen":
    st.header("üì∑ Clasificaci√≥n de Imagen")

    archivo = st.file_uploader("Sube una imagen", type=["jpg", "jpeg", "png"])

    if archivo is not None:
        imagen = Image.open(archivo).convert("RGB").resize(IMAGE_SIZE)
        st.image(imagen, caption="Imagen cargada", use_container_width=False)

        # Convertir a array y expandir dimensi√≥n
        x = np.asarray(imagen, dtype="float32")
        x = np.expand_dims(x, axis=0)  # Para que tenga shape (1, H, W, 3)
        
        
        # Preprocesar imagen usando tu funci√≥n
        x, _ = preprocess_images(x, flatten=True)  # Aqu√≠ NO aplanamos, porque el modelo espera (1, H, W, 3)

        with st.spinner("Generando predicci√≥n ‚Ä¶"):
            pred = load_image_model().predict(x, verbose=0)
            idx = int(np.argmax(pred, axis=-1))
            clase = IMAGE_CLASS_NAMES[idx]
            conf = float(np.max(pred))

        st.success(f"**Predicci√≥n:** {clase}")
        st.caption(f"Confianza: {conf:.3f}")

# ------------------ P√ÅGINA: TEXTO ----------------------------

elif pagina == "Clasificaci√≥n de Texto":
    st.header("üìù Sentiment Analysis (1 = positivo, 0 = negativo)")

    texto = st.text_area(
        "Ingresa una oraci√≥n:",
        placeholder="Hoy fue un gran d√≠a para aprender Streamlit!",
    )

    if st.button("Predecir") and texto.strip():
        tok = load_tokenizer()
        seq = tok.texts_to_sequences([texto])
        tf = _lazy_tf()
        seq_pad = tf.keras.preprocessing.sequence.pad_sequences(
            seq, maxlen=TEXT_MAXLEN, padding="post"
        )

        with st.spinner("Generando predicci√≥n ‚Ä¶"):
            prob_pos = float(load_text_model().predict(seq_pad, verbose=0)[0][0])
            label = 1 if prob_pos >= 0.5 else 0
        prediccion_texto = "Positive review"
        if label == 1:
            prediccion_texto = prediccion_texto
        else:
            prediccion_texto = "Negative review"
        st.success(f"**Predicci√≥n:** {prediccion_texto}")
        st.caption(f"Probabilidad positiva: {prob_pos:.3f}")

# ------------------ P√ÅGINA: REGRESI√ìN ------------------------
else:
    st.header("üìà Predicci√≥n de Regresi√≥n")
    st.write("Se utiliz√≥ el dataset Diabetes de skelearn")
    st.write("Introduce las variables num√©ricas del modelo:")

    with st.form("reg_form"):
        valores = []
        for f in FEATURE_NAMES:
            if f == "sex":
                sexo = st.selectbox("Sexo (F = Femenino, M = Masculino):", ["F", "M"])
                valores.append(1.0 if sexo == "M" else 0.0)
            elif f == "age":
                valor = st.number_input(f, min_value=0, max_value=120, step=1, value=0)
                valores.append(int(valor))
            else:
                valor = st.number_input(f, value=0.0, format="%.4f")
                valores.append(valor)
        enviar = st.form_submit_button("Predecir")

    if enviar:
        x = np.array(valores, dtype="float32").reshape(1, -1)
        scaler = load_scaler()
        if scaler is not None:
            x = scaler.transform(x)
        with st.spinner("Generando predicci√≥n ‚Ä¶"):
            y = load_regression_model().predict(x)
        st.success(f"**Valor predicho:** {float(y[0]):.4f}")

#activar entorno virtual
#.\tfenv\Scripts\python.exe -c "import sys; print(sys.executable)"

#ejecutar:
#.\tfenv\Scripts\python.exe -m streamlit run streamlit_app.py
